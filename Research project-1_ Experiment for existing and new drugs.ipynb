{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#PU_Learning starts\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "url = \"/Volumes/Farhan/Research/Code/Meta-path/DDID/data/drug_data_new.csv\"\n",
    "\n",
    "data = pd.read_csv(url, skiprows=1, header=None)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82215, 27)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data.fillna(0)\n",
    "\n",
    "#slc_3 = np.r_[:,30]\n",
    "slc = np.r_[:, 2:8]\n",
    "#slc = np.r_[:, 2]\n",
    "slc_2 = np.r_[:, 8:26]\n",
    "\n",
    "#data[slc_3] = data[slc_3].astype(int)\n",
    "\n",
    "#print(type(data))\n",
    "data[slc] = data[slc].astype(int)\n",
    "data[slc_2] = data[slc_2].astype(np.float64)\n",
    "\n",
    "\n",
    "#data.loc[1001]\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46758\n",
       "1    35457\n",
       "Name: 26, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data[data[30] == 0].sample(n=6880)\n",
    "df2 = data[data[30] == 1].sample(n=6880)\n",
    "\n",
    "frames = [df1, df2]\n",
    "\n",
    "data = pd.concat(frames)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = data.iloc[:,2:30]\n",
    "y_data = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfeature.utility import construct_W\n",
    "\n",
    "\n",
    "kwargs_W = {\"metric\":\"euclidean\",\"neighbor_mode\":\"knn\",\"weight_mode\":\"heat_kernel\",\"k\":5,'t':1}\n",
    "\n",
    "\n",
    "W = construct_W.construct_W(x_data, **kwargs_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier(silent=False)\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "\n",
    "model = cb.CatBoostClassifier()\n",
    "\n",
    "#model.fit(x_train, y_train)\n",
    "model.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators = 1000,  # 1000 trees\n",
    "    n_jobs = -1           # Use all CPU cores\n",
    ")\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predict = model.predict(x_test)\n",
    "y_predict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, accuracy_score, f1_score, average_precision_score, precision_recall_curve\n",
    "\n",
    "def evaluate_results(y_test, y_predict):\n",
    "    print('Classification results:')\n",
    "    f1 = f1_score(y_test, y_predict)\n",
    "    print(\"f1: %.2f%%\" % (f1 * 100.0)) \n",
    "    roc = roc_auc_score(y_test, y_predict)\n",
    "    print(\"roc: %.2f%%\" % (roc * 100.0)) \n",
    "    rec = recall_score(y_test, y_predict, average='binary')\n",
    "    print(\"recall: %.2f%%\" % (rec * 100.0)) \n",
    "    prc = precision_score(y_test, y_predict, average='binary')\n",
    "    print(\"precision: %.2f%%\" % (prc * 100.0)) \n",
    "    aupr = average_precision_score(y_test, y_predict)\n",
    "    print(\"AUPR: %.2f%%\" % (aupr * 100.0))  \n",
    "    \n",
    "#evaluate_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-class svm for imbalanced binary classification\n",
    "#OneClassSVM v2.0\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# generate dataset\n",
    "url = \"drug_data_2.csv\"\n",
    "data = pd.read_csv(url, header=None, skiprows=1)\n",
    "\n",
    "df1 = data[data[30] == 0].sample(n=6880*9)\n",
    "df2 = data[data[30] == 1].sample(n=6880)\n",
    "\n",
    "frames = [df1, df2]\n",
    "\n",
    "data = pd.concat(frames)\n",
    "\n",
    "\n",
    "x_data = data.iloc[:,2:30]\n",
    "y_data = data.iloc[:,-1]\n",
    "\n",
    "print(data.iloc[:, -1].value_counts())\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=7)\n",
    "trainX, testX, trainy, testy = train_test_split(x_data, y_data, test_size=0.2, random_state=7)\n",
    "\n",
    "\n",
    "# define outlier detection model\n",
    "model = OneClassSVM(gamma='scale', nu=0.01)\n",
    "# fit on majority class\n",
    "trainX = trainX[trainy==1]\n",
    "model.fit(trainX)\n",
    "# detect outliers in the test set\n",
    "yhat = model.predict(testX)\n",
    "# mark inliers 1, outliers -1\n",
    "testy[testy == 1] = 1\n",
    "testy[testy == 0] = -1\n",
    "# calculate score\n",
    "evaluate_results(testy, yhat)\n",
    "#score = f1_score(testy, yhat)\n",
    "#print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the reason for choosing this index is it splits the dataset into \n",
    "#training_set=data.iloc[0:60571521,:]\n",
    "#testing_set=data.iloc[60571521:,:]\n",
    "training_set=data.iloc[0:40188,:]\n",
    "testing_set=data.iloc[40188:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "\n",
    "train_1 = training_set[training_set[28] == 0].sample(n=19200)\n",
    "train_2 = training_set[training_set[28] == 1].sample(n=19200)\n",
    "\n",
    "index_1 = train_1.index\n",
    "indices_1_list = index_1.tolist()\n",
    "\n",
    "index_2 = train_2.index\n",
    "indices_2_list = index_2.tolist()\n",
    "\n",
    "\n",
    "data = data.drop(index=indices_1_list)\n",
    "data = data.drop(index=indices_2_list)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "test_1 = testing_set[testing_set[28] == 0].sample(n=4800)\n",
    "test_2 = testing_set[testing_set[28] == 1].sample(n=4800)\n",
    "\n",
    "train_frames = [train_1, train_2]\n",
    "test_frames = [train_1, train_2]\n",
    "\n",
    "train_frames = sklearn.utils.shuffle(train_frames)\n",
    "test_frames = sklearn.utils.shuffle(test_frames)\n",
    "\n",
    "train = pd.concat(train_frames)\n",
    "test = pd.concat(test_frames)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54215, 27)\n",
      "(26215, 27)\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "\n",
    "train_1 = data[data[26] == 0].sample(n=28000)\n",
    "train_2 = data[data[26] == 1].sample(n=28000)\n",
    "\n",
    "index_1 = train_1.index\n",
    "indices_1_list = index_1.tolist()\n",
    "\n",
    "index_2 = train_2.index\n",
    "indices_2_list = index_2.tolist()\n",
    "\n",
    "data = data.drop(index=indices_1_list)\n",
    "print(data.shape)\n",
    "\n",
    "data = data.drop(index=indices_2_list)\n",
    "print(data.shape)\n",
    "\n",
    "test_1 = data[data[26] == 0].sample(n=7000)\n",
    "test_2 = data[data[26] == 1].sample(n=7000)\n",
    "\n",
    "train_frames = [train_1, train_2]\n",
    "test_frames = [train_1, train_2]\n",
    "\n",
    "train_frames = sklearn.utils.shuffle(train_frames)\n",
    "test_frames = sklearn.utils.shuffle(test_frames)\n",
    "\n",
    "train = pd.concat(train_frames)\n",
    "test = pd.concat(test_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    28000\n",
       "0    28000\n",
       "Name: 26, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:, -1].value_counts()\n",
    "test.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = train.iloc[:,2:26]\n",
    "trainy = train.iloc[:,-1]\n",
    "\n",
    "testX = test.iloc[:,2:26]\n",
    "testy = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [4,10,16,22,6,12,18,24]\n",
    "\n",
    "trainX = train.iloc[:,features]\n",
    "trainy = train.iloc[:,-1]\n",
    "\n",
    "testX = test.iloc[:,features]\n",
    "testy = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy[testy == 1] = 1\n",
    "testy[testy == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = DDI_train_n2v\n",
    "trainy = DDI_train_label\n",
    "trainX = DDI_train_n2v\n",
    "trainy = DDI_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "import pandas as pd\n",
    "\n",
    "# define outlier detection model\n",
    "model = OneClassSVM(gamma='scale', nu=0.01)\n",
    "# fit on majority class\n",
    "trainX = trainX[trainy==1]\n",
    "model.fit(trainX)\n",
    "# detect outliers in the test set\n",
    "yhat = model.predict(testX)\n",
    "# mark inliers 1, outliers -1\n",
    "testy[testy == 1] = 1\n",
    "testy[testy == 0] = -1\n",
    "# calculate score\n",
    "evaluate_results(testy, yhat)\n",
    "#score = f1_score(testy, yhat)\n",
    "#print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier(silent=False)\n",
    "\n",
    "model.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "\n",
    "model = cb.CatBoostClassifier()\n",
    "\n",
    "model.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators = 1000,  # 1000 trees\n",
    "    n_jobs = -1           # Use all CPU cores\n",
    ")\n",
    "model.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "f1: 53.26%\n",
      "roc: 63.20%\n",
      "recall: 41.94%\n",
      "precision: 72.97%\n",
      "AUPR: 59.63%\n"
     ]
    }
   ],
   "source": [
    "evaluate_results(testy, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "sc_x = StandardScaler() \n",
    "x_train = sc_x.fit_transform(x_train)  \n",
    "x_test = sc_x.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "  \n",
    "print (\"Confusion Matrix : \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(trainX,trainy)\n",
    "\n",
    "#\n",
    "y_pred=logreg.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "f1: 58.40%\n",
      "roc: 64.09%\n",
      "recall: 50.42%\n",
      "precision: 69.39%\n",
      "AUPR: 59.78%\n"
     ]
    }
   ],
   "source": [
    "evaluate_results(testy, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "regressor = GradientBoostingRegressor(\n",
    "    max_depth=2,\n",
    "    n_estimators=3,\n",
    "    learning_rate=1.0\n",
    ")\n",
    "regressor.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [mean_squared_error(testy, y_pred) for y_pred in regressor.staged_predict(testX)]\n",
    "best_n_estimators = np.argmin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor = GradientBoostingRegressor(\n",
    "    max_depth=2,\n",
    "    n_estimators=best_n_estimators,\n",
    "    learning_rate=1.0\n",
    ")\n",
    "best_regressor.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "f1: 63.60%\n",
      "roc: 64.32%\n",
      "recall: 62.35%\n",
      "precision: 64.91%\n",
      "AUPR: 59.30%\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_regressor.predict(testX)\n",
    "\n",
    "evaluate_results(testy, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [4,10,16,22,6,12,18,24]\n",
    "\n",
    "trainX = train.iloc[:,features]\n",
    "trainy = train.iloc[:,-1]\n",
    "\n",
    "testX = test.iloc[:,features]\n",
    "testy = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "f1: 99.81%\n",
      "roc: 99.81%\n",
      "recall: 99.70%\n",
      "precision: 99.93%\n",
      "AUPR: 99.78%\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(testX)\n",
    "\n",
    "evaluate_results(testy, predictions.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "f1: 99.81%\n",
      "roc: 99.81%\n",
      "recall: 99.67%\n",
      "precision: 99.96%\n",
      "AUPR: 99.79%\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt.predict(testX)\n",
    "evaluate_results(testy, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "trainX = sc.fit_transform(trainX)\n",
    "testX = sc.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting classifier to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 2)\n",
    "classifier.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results:\n",
      "f1: 80.17%\n",
      "roc: 83.44%\n",
      "recall: 66.96%\n",
      "precision: 99.88%\n",
      "AUPR: 83.40%\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(testX)\n",
    "evaluate_results(testy, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
